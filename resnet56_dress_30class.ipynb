{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specification\n",
    "Model: scratch resnet56 | Data: 30 classes | Dropout:  | Max Size:  | Remarks: Using techniques of superconvergence and follow steps in tutorial\n",
    "\n",
    "Result: \n",
    "\n",
    "Issues: Cudo out of memory\n",
    "\n",
    "Reference: https://github.com/sgugger/Deep-Learning/blob/master/Cyclical%20LR%20and%20momentums.ipynb\n",
    "\n",
    "[24/01/2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/r8user2/fastai/old')\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/r8user2/Documents/HY/dress_data/alex_workplace/dressdata_project/git_workplace/selected_gd_data_30'\n",
    "CPU_WORKERS = 60\n",
    "sz = 224\n",
    "# stats may need to adjust\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs = 64):\n",
    "    tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()])\n",
    "    return ImageClassifierData.from_paths(PATH, \n",
    "                                          trn_name = 'imgtrain',\n",
    "                                          val_name = 'imgval',\n",
    "                                          test_name = 'imgtest',\n",
    "                                          test_with_labels = True,\n",
    "                                          num_workers = CPU_WORKERS,\n",
    "                                          tfms=tfms, \n",
    "                                          bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Resnet56 From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, ch_in, ch_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(ch_out)\n",
    "        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ch_out)\n",
    "        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or ch_in != ch_out:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(ch_out)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn2(self.conv2(F.relu(self.bn1(out))))\n",
    "        out += shortcut\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change num_classes!\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=30):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self.make_group_layer(16, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self.make_group_layer(16, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self.make_group_layer(32, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_group_layer(self,ch_in, ch_out, num_blocks, stride):\n",
    "        layers = [BasicBlock(ch_in, ch_out, stride)]\n",
    "        for i in range(num_blocks-1):\n",
    "            layers.append(BasicBlock(ch_out, ch_out, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return F.log_softmax(self.linear(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ResNet([9,9,9]), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Weight Decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_wds(wds):\n",
    "    learn = ConvLearner.from_model_data(ResNet([9,9,9]), data)\n",
    "    learn.crit = F.nll_loss\n",
    "    learn.lr_find2(wds = wds,start_lr = 1e-4, end_lr = 100,num_it = 100)\n",
    "    trn_loss = learn.sched.losses\n",
    "    lrsw = learn.sched.lrs\n",
    "    return trn_loss, lrsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loss1, lrsw1 = fix_wds(wds = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
